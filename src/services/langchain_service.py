from typing import Dict, List, Any
from typing import Dict, List, Any

from langchain_openai import ChatOpenAI


from langchain_groq import ChatGroq
from langchain_core.prompts.chat import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langgraph.graph import StateGraph, END
from dotenv import load_dotenv
import os

from src.database.models.chat_history_model import ChatHistory
from src.database.models.user_profile_model import UserProfile
from sqlalchemy.orm import Session
from src.services.emotion_service import analyze_emotion


from src.rag_system.system.rag_core import obtener_contexto_rag


load_dotenv()


#api_key = os.getenv("GROQ_API_KEY")
api_key = os.getenv("OPENAI_API_KEY")


# Definir el estado del grafo
class ChatState(Dict[str, Any]):
    messages: List[ChatHistory | Dict]  # Lista de mensajes en el chat
    input: str
    emotion: str
    profile: str
    chroma_context: str

    user_id: str  # Nueva


model_name = 'gpt-4o-mini'
#model_name = 'llama-3.1-8b-instant'
#llm = ChatGroq(model=model_name, api_key=api_key, temperature=0.3)
llm = ChatOpenAI(model=model_name, api_key=api_key, temperature=0.3)


# Prompt y extractor para detecci贸n de informaci贸n personal relevante
extraction_prompt = ChatPromptTemplate.from_messages([
    ("system", 
     "Eres un asistente que extrae informaci贸n personal relevante del usuario. "
     "Si el mensaje incluye informaci贸n como nombre, cumplea帽os, estudios, trabajo, hobbies u otros datos personales importantes del USUARIO solamente, NO del asistente, "
     "Responde NICAMENTE con un JSON v谩lido. No escribas nada fuera del JSON. con los campos extra铆dos."
     "Si no hay informaci贸n relevante, devuelve un JSON vac铆o '{}'."
     "Ejemplo de que no debes hacer: {{'nombre': 'no especificado'}}"
     "Si el nombre o cualquier dato no fu茅 especificado solo entrega un JSON vac铆o."
     "Solo quiero que entregues la info del usuario, que toda est茅 especificada."
     "Ejemplo de que debes hacer: Pregunta:  hola, hoy me fue bien en la universidad, estoy estudiando ingeniera de sistemas, Respuesta: {{'estudios': 'ingenier铆a de sistemas'}}"
    ),
    ("human", "{input}")
])


extractor = extraction_prompt | llm | JsonOutputParser()



# Prompt y runnable para el chatbot
prompt = ChatPromptTemplate.from_messages([
   ("system", """
MODO CRISIS- Si detectas palabras de riesgo como: 'morirme', 'suicidio', etc:
1. Cambia INMEDIATAMENTE a tono serio, directo y sin emojis
2. Extrae del {chroma_context} la informaci贸n de:
   - Consultorio Psicol贸gico (horarios, correo, tel茅fono)
   - Ruta de Salud Mental
   - IPS o centros de atenci贸n inmediata
   
2. Responde SERIAMENTE:
Esto que me cuantas es muy importante y me importa mucho tu bienestar.

 NECESITAS AYUDA INMEDIATA:
 Universidad del Valle - Tulu谩: [extrae del chroma_context]
   
   Tu vida tiene valor. Por favor, contacta estos recursos AHORA. No est谩s solo/a.

3. CERO humor, CERO met谩foras en estos casos
4. Termina la conversaci贸n amablemente, sin m谩s chistes ni met谩foras.
5. Si el usuario insiste en hablar de suicidio, repite los recursos sin agregar contenido nuevo.

------

MODO AMIGO - En cualquier otro caso:
 
Regla 1: Temas fuera de bienestar emocional universitario

SI el usuario pregunta sobre temas no relacionados con bienestar emocional universitario:
   Tines PROHIBIDO que le expliques sobre el tema, darle informaci贸n t茅cnica o utilizar met谩foras
   
   Debes responder con:
   "Uy [nombre si lo conoces], [tema] no es lo m铆o  Mi rollo es el apoyo emocional en la U. 驴C贸mo vas con el estr茅s acad茅mico o hay algo que te preocupe emocionalmente?"
   
Regla 2: Bienestar emocional universitario

Si el usuario habla sobre estr茅s acad茅mico, ansiedad por ex谩menes, adaptaci贸n universitaria, procrastinaci贸n, soledad estudiantil, presi贸n de estudios, etc:
Eres un amigo divertido que habla espa帽ol. 
Tu papel es ser un amigo cercano que brinda bienestar emocional universitario.

Personalidad:
- Lenguaje 100% de amigo, 0% de psic贸logo
- Incluye met谩foras divertidas o humor ligero cuando sea apropiado
- Usa 0-3 emojis para calidez 
- Mant茅n ternura y calidez siempre

ADAPTACIN EMOCIONAL:
Emoci贸n detectada: {emotion}
Perfil del usuario: {profile} 
Responde como ese amigo que te hace re铆r incluso en d铆as malos. Equilibra la comprensi贸n con momentos ligeros.

Usa el contexto {chroma_context} como un amigo compartiendo experiencia, NO como experto.
IDENTIFICA 1-2 t茅cnicas/consejos pr谩cticos del contexto
TRANSFRMALOS en lenguaje de amigo

PROHIBICIONES FINALES:
- NO expliques temas fuera de bienestar universitario
- NO uses m谩s de 2 oraciones para redirigir
- NO suenes como terapeuta profesional
- Mant茅n respuestas concisas (m谩ximo 3-5 oraciones)

 """
),
("placeholder", "{history}"),
("human", "{input}")

])


runnable = prompt | llm | StrOutputParser()



# Nodo del grafo: procesa un turno de conversaci贸n

def chatbot_node(state: ChatState) -> ChatState:
    history_msgs: List[Any] = []
    
    # Mapeando datos del historial a base de IA
    for chat in state.get("messages", []):
        history_msgs.append(HumanMessage(content=chat.question))
        history_msgs.append(AIMessage(content=chat.answer))
        
        
        
    # rag_context = obtener_contexto_rag(state["input"])
    
    ###
    """ print(" CONTEXTO CHROMA (chatbot_node):")
    print(f"Input: {state['input']}")
    print("=" * 50) """

    
    # print("History:", history_msgs)
    response = runnable.invoke({"history": history_msgs,
                                "input": state["input"], 
                                "emotion": state.get("emotion", "others"),
                               "chroma_context": state.get("chroma_context", ""),
                               "profile": state.get("profile", "")
                               })
    state["messages"].append({"role": "assistant", "content": response})

    print(f"Contexto obtenido: {state.get('chroma_context', '')}")
    print(f"mensajes: {state['messages']}")



    return state


graph = StateGraph(ChatState)
graph.add_node("chatbot", chatbot_node)
graph.set_entry_point("chatbot")
graph.set_finish_point("chatbot")

chatbot_graph = graph.compile()




def response_chatbot(message: str, chat_memory: List[ChatHistory], user_id: int, db: Session) -> Dict[str, str]:
    """
    Funci贸n para obtener la respuesta del chatbot, extraer informaci贸n personal y guardar en la base de datos.
    """
    # 1. Detectar emoci贸n
    emotion = analyze_emotion(message)
    print(f"Emoci贸n detectada: {emotion}")

    # 2. Extraer informaci贸n personal (si la hay)
    try:
        extracted_info = extractor.invoke({"input": message})
    except Exception:
        extracted_info = {}
    print(f"Informaci贸n extra铆da: {extracted_info}")
    
    if extracted_info and extracted_info != {}:
        for key, value in extracted_info.items():
            db.add(UserProfile(user_id=user_id, key=key, value=value))
        db.commit()

    # 3. Preparar contexto: historial + perfil de usuario
    user_profile = db.query(UserProfile).filter_by(user_id=user_id).all()
    profile_context = "\n".join([f"{p.key}: {p.value}" for p in user_profile])

    rag_context: str = obtener_contexto_rag(message)
    state = {
        "messages": chat_memory,
        "input": message,
        "emotion": emotion,
        "profile": profile_context, 
        "chroma_context": rag_context,
    }

    # 4. Incluir perfil en el prompt
    final_state = chatbot_graph.invoke(state)
    response = final_state["messages"][-1]["content"]  # 煤ltimo mensaje del asistente
    return {"response": response, "emotion": emotion}
