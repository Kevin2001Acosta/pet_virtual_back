from typing import Dict, List, Any
from langchain_groq import ChatGroq
from langchain_core.prompts.chat import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langgraph.graph import StateGraph, END
from dotenv import load_dotenv
import os

from src.database.models.chat_history_model import ChatHistory
from src.database.models.user_profile_model import UserProfile
from sqlalchemy.orm import Session
from src.services.emotion_service import analyze_emotion


from src.rag_system.system.rag_core import obtener_contexto_rag


load_dotenv()

api_key = os.getenv("GROQ_API_KEY")


# Definir el estado del grafo
class ChatState(Dict[str, Any]):
    messages: List[ChatHistory]  # Lista de mensajes en el chat
    input: str
    
    user_id: str #Nueva
    


model_name = 'llama-3.1-8b-instant'

llm = ChatGroq(model=model_name, api_key=api_key, temperature=0.1)

# Prompt y extractor para detecci贸n de informaci贸n personal relevante
extraction_prompt = ChatPromptTemplate.from_messages([
    ("system", 
     "Eres un asistente que extrae informaci贸n personal relevante del usuario. "
     "Si el mensaje incluye informaci贸n como nombre, cumplea帽os, estudios, trabajo, hobbies u otros datos personales importantes del USUARIO solamente, NO del asistente, "
     "Responde NICAMENTE con un JSON v谩lido. No escribas nada fuera del JSON. con los campos extra铆dos."
     "Si no hay informaci贸n relevante, devuelve un JSON vac铆o '{}'."
     "Ejemplo de que no debes hacer: {{'nombre': 'no especificado'}}"
     "Si el nombre o cualquier dato no fu茅 especificado solo entrega un JSON vac铆o."
     "Solo quiero que entregues la info del usuario, que toda est茅 especificada."
     "Ejemplo de que debes hacer: Pregunta:  hola, hoy me fue bien en la universidad, estoy estudiando ingeniera de sistemas, Respuesta: {{'estudios': 'ingenier铆a de sistemas'}}"
    ),
    ("human", "{input}")
])


extractor = extraction_prompt | llm | JsonOutputParser()



# Prompt y runnable para el chatbot
prompt = ChatPromptTemplate.from_messages([
   ("system", 
 "MODO CRISIS- Si detectas palabras de riesgo ('morirme', 'suicidio', etc.):"
"1. Busca en {chroma_context} recursos espec铆ficos de UniValle"
"2. Responde SERIAMENTE:"
"   'Esto es importante. Recursos de UniValle:'"
"   '[Info de psic贸logos del contexto]'"
"   'Tu vida importa. Busca ayuda profesional AHORA.'"
"3. CERO humor, CERO met谩foras en estos casos"
"4. Termina la conversaci贸n amablemente, sin m谩s chistes ni met谩foras."
"5. Si el usuario insiste en hablar de suicidio, repite los recursos y termina la conversaci贸n.\n\n"

"MODO AMIGO En cualquier otro caso:"
 "Eres un amigo divertido que habla espa帽ol. "
 "Tu papel es ser un amigo cercano que brinda bienestar emocional."
 "DEBES incluir al menos una met谩fora divertida o un toque de HUMOR ligero y juguet贸n en CADA respuesta que no sea de crisis. Siempre mant茅n la ternura y la calidez."
 "Lenguaje 100% de amigo, 0% de psic贸logo."
 "Incluye 0-3 emojis en algunas respuestas para hacerlas m谩s c谩lidas y expresivas ."
 "Adapta tu tono seg煤n la emoci贸n detectada: {emotion} y la informaci贸n del usuario: {profile}. "
 "Responde como ese amigo que te hace re铆r incluso en d铆as malos. Equilibra la comprensi贸n con momentos ligeros."
 "Usa el contexto {chroma_context}, pero no como un experto, sino como un amigo que comparte desde su experiencia y calidez. "
 "IDENTIFICA 1-2 t茅cnicas/consejos pr谩cticos del contexto"
 "TRANSFRMALOS en lenguaje de amigo: 'Oye, probemos esto...' o 'A m铆 me funcion贸...'"
 "Mant茅n un estilo cercano, juguet贸n y positivo, pero tambi茅n sensible cuando la situaci贸n lo requiera."
 "Mant茅n tus respuestas concisas - m谩ximo 3-6 oraciones. S茅 directo pero c谩lido." 
 "Tienes prohibido sonar como un terapeuta o psic贸logo profesional."
 "IMPORTANTE: Enf贸cate NICAMENTE en temas de bienestar emocional universitario: estr茅s acad茅mico, ex谩menes, vida estudiantil, adaptaci贸n a la universidad."
 "Si el usuario pregunta sobre temas NO relacionados con bienestar universitario (como Python, programaci贸n, econom铆a, etc.), responde amablemente que solo puedes ayudar con temas de bienestar emocional estudiantil."
),
("placeholder", "{history}"),
("human", "{input}")

])


runnable = prompt | llm | StrOutputParser()



# Nodo del grafo: procesa un turno de conversaci贸n

def chatbot_node(state: ChatState) -> ChatState:
    history_msgs: List[Any] = []
    
    # Mapeando datos del historial a base de IA
    for chat in state.get("messages", []):
        history_msgs.append(HumanMessage(content=chat.question))
        history_msgs.append(AIMessage(content=chat.answer))
        
        
        
    # rag_context = obtener_contexto_rag(state["input"])
    
    ###
    print(" CONTEXTO CHROMA (chatbot_node):")
    print(f"Input: {state['input']}")
    print(f"Contexto obtenido: {state.get('chroma_context', '')}")
    print("=" * 50)

    
    # print("History:", history_msgs)
    response = runnable.invoke({"history": history_msgs,
                                "input": state["input"], 
                                "emotion": state.get("emotion", "others"),
                               "chroma_context": state.get("chroma_context", "")
                               })
    state["messages"].append({"role": "assistant", "content": response})



    return state


graph = StateGraph(ChatState)
graph.add_node("chatbot", chatbot_node)
graph.set_entry_point("chatbot")
graph.set_finish_point("chatbot")

chatbot_graph = graph.compile()




def response_chatbot(message: str, chat_memory: List[ChatHistory], user_id: int, db: Session) -> Dict[str, str]:
    """
    Funci贸n para obtener la respuesta del chatbot, extraer informaci贸n personal y guardar en la base de datos.
    """
    # 1. Detectar emoci贸n
    emotion = analyze_emotion(message)
    print(f"Emoci贸n detectada: {emotion}")

    # 2. Extraer informaci贸n personal (si la hay)
    try:
        extracted_info = extractor.invoke({"input": message})
    except Exception:
        extracted_info = {}
    print(f"Informaci贸n extra铆da: {extracted_info}")
    
    if extracted_info and extracted_info != {}:
        for key, value in extracted_info.items():
            db.add(UserProfile(user_id=user_id, key=key, value=value))
        db.commit()

    # 3. Preparar contexto: historial + perfil de usuario
    user_profile = db.query(UserProfile).filter_by(user_id=user_id).all()
    profile_context = "\n".join([f"{p.key}: {p.value}" for p in user_profile])
    
    rag_context = obtener_contexto_rag(message)
    
    ###
    """
    print(" CONTEXTO CHROMA (response_chatbot):")
    print(f"Input: {message}")  
    print(f"Contexto obtenido: {rag_context}")
    print("=" * 50) 
    """

    state = {
        "messages": chat_memory,
        "input": message,
        "emotion": emotion,
        "profile": profile_context, 
        "chroma_context": rag_context,
        
        
    }

    # 4. Incluir perfil en el prompt
    final_state = chatbot_graph.invoke(state)
    response = final_state["messages"][-1]["content"]  # 煤ltimo mensaje del asistente
    return {"response": response, "emotion": emotion}
